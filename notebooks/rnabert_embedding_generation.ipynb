{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup directories and install dependencies\n",
        "!mkdir -p \"rnabert_embeddings\"\n",
        "%pip install multimolecule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from multimolecule import RnaTokenizer, RnaBertModel\n",
        "import re\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RNABERT embedding model class\n",
        "class RNABERTEmbeddingModel:\n",
        "    def __init__(self, model_name=\"multimolecule/rnabert\", max_length=440):\n",
        "        self.model_name = model_name\n",
        "        self.max_length = max_length\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.tokenizer = RnaTokenizer.from_pretrained(\n",
        "            model_name,\n",
        "            bos_token=None,\n",
        "            eos_token=None\n",
        "        )\n",
        "        self.model = RnaBertModel.from_pretrained(\n",
        "            model_name,\n",
        "            bos_token_id=None,\n",
        "            eos_token_id=None\n",
        "        )\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "    \n",
        "    def preprocess_rna_sequence(self, rna_sequence):\n",
        "        if not isinstance(rna_sequence, str) or len(rna_sequence) == 0:\n",
        "            return \"\"\n",
        "        \n",
        "        rna_sequence = rna_sequence.upper()\n",
        "        rna_sequence = re.sub(r\"[^AUCG]\", \"N\", rna_sequence)\n",
        "        \n",
        "        return rna_sequence\n",
        "    \n",
        "    def encode_sequences(self, rna_sequences):\n",
        "        preprocessed_sequences = [self.preprocess_rna_sequence(seq) for seq in rna_sequences]\n",
        "        \n",
        "        encodings = self.tokenizer(\n",
        "            preprocessed_sequences,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length\n",
        "        )\n",
        "        \n",
        "        return {key: tensor.to(self.device) for key, tensor in encodings.items()}\n",
        "    \n",
        "    def get_embeddings(self, encodings):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**encodings)\n",
        "            last_hidden_states = outputs.last_hidden_state\n",
        "            attention_mask = encodings['attention_mask']\n",
        "            \n",
        "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()\n",
        "            sum_embeddings = torch.sum(last_hidden_states * mask_expanded, dim=1)\n",
        "            sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)\n",
        "            mean_embeddings = sum_embeddings / sum_mask\n",
        "            \n",
        "            return mean_embeddings.cpu().numpy()\n",
        "    \n",
        "    def process_batch(self, rna_sequences):\n",
        "        encodings = self.encode_sequences(rna_sequences)\n",
        "        embeddings = self.get_embeddings(encodings)\n",
        "        return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize RNABERT model\n",
        "embedding_model = RNABERTEmbeddingModel()\n",
        "print(f\"Using device: {embedding_model.device}\")\n",
        "print(f\"Model hidden size: {embedding_model.model.config.hidden_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "DATA_PATH = \"data/human_sequence_data.csv\"\n",
        "REQUIRED_COLUMNS = [\"ORF\"]\n",
        "\n",
        "sequence_dataframe = pd.read_csv(DATA_PATH, usecols=REQUIRED_COLUMNS)\n",
        "\n",
        "rna_sequences = [\n",
        "    str(orf_sequence).replace('T', 'U') if isinstance(orf_sequence, str) else \"\"\n",
        "    for orf_sequence in sequence_dataframe[\"ORF\"]\n",
        "]\n",
        "\n",
        "print(f\"Loaded {len(rna_sequences)} RNA sequences\")\n",
        "print(f\"Average RNA length: {np.mean([len(seq) for seq in rna_sequences if seq]):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure batch processing parameters\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "dataset_size = len(rna_sequences)\n",
        "total_batches = (dataset_size + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "print(f\"Dataset size: {dataset_size}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Total batches: {total_batches}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate embeddings in batches\n",
        "for batch_index in tqdm(range(total_batches), desc=\"Processing batches\"):\n",
        "    start_index = batch_index * BATCH_SIZE\n",
        "    end_index = min(start_index + BATCH_SIZE, dataset_size)\n",
        "    \n",
        "    batch_rna_sequences = rna_sequences[start_index:end_index]\n",
        "    \n",
        "    batch_embeddings = embedding_model.process_batch(batch_rna_sequences)\n",
        "    \n",
        "    embeddings_path = f\"rnabert_embeddings/batch_{batch_index:04d}.npy\"\n",
        "    np.save(embeddings_path, batch_embeddings)\n",
        "    \n",
        "    del batch_embeddings, batch_rna_sequences\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Embedding generation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify generated embeddings\n",
        "sample_embeddings = np.load(\"rnabert_embeddings/batch_0000.npy\")\n",
        "\n",
        "print(f\"Sample embeddings shape: {sample_embeddings.shape}\")\n",
        "print(f\"Embedding dimension: {sample_embeddings.shape[1]}\")\n",
        "print(f\"Batch size: {sample_embeddings.shape[0]}\")\n",
        "print(f\"Sample embedding norm: {np.linalg.norm(sample_embeddings[0]):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python merge_batches.py -b \"rnabert_embeddings/\" -o \"rnabert_embeddings/merged_embeddings.npy\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
